import re
import time
import httpx
import asyncio
import logging
import certifi
import requests
import threading
import random
from datetime import timedelta, date, datetime

from src.config import Config
from src.sqlite import SQLite
from src.get_headers import getHeaders

logger = logging.getLogger(__name__)

class BCZ:
    def __init__(self, config: Config) -> None:
        '''å°ç­è§£æç±»'''
        self.config = config
        self.invalid_pattern = r'[\000-\010]|[\013-\014]|[\016-\037]'
        self.own_info_url = 'https://social.baicizhan.com/api/deskmate/home_page'
        self.group_list_url = 'https://group.baicizhan.com/group/own_groups'
        self.group_detail_url = 'https://group.baicizhan.com/group/information'
        self.user_deskmate_url = 'https://social.baicizhan.com/api/deskmate/social/get_user_deskmate_info'
        self.user_card_info = 'https://social.baicizhan.com/api/deskmate/personal_details'
        self.user_team_url = 'https://activity.baicizhan.com/api/activity/team-up-recite/person_home' # æ³¨æ„å‚æ•°å­—æ®µåbcz_id
        self.get_week_rank_url = 'https://group.baicizhan.com/group/get_week_rank'
        self.remove_members_url = 'https://group.baicizhan.com/group/remove_members'

        self.default_headers = {
            "default_headers_dict": {
                "Connection": "keep-alive",
                "User-Agent": "bcz_app_android/7060100 android_version/12 device_name/DCO-AL00 - HUAWEI",
                "Accept": "*/*",
                "Origin": "",
                "X-Requested-With": "",
                "Sec-Fetch-Site": "same-site",
                "Sec-Fetch-Mode": "cors",
                "Sec-Fetch-Dest": "empty",
                "Referer": "",
                "Accept-Encoding": "gzip, deflate",
                "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7"
            }
        }
        self.default_cookie = {
            "access_token": "",
            "client_time": "",
            "app_name": "7060100",
            "bcz_dmid": "2a16dfbb",
            "channel": "qq",
            # device_id åº”æ ¹æ®access_tokenä½¿ç”¨å“ˆå¸Œå”¯ä¸€ç¡®å®š
            "device_id": "",
            "device_name": "android/DCO-AL00-HUAWEI",
            "device_version": "12",
            "Pay-Support-H5": "alipay_mob_client"
        }
        self.hash_rmb = {}
        self.buffered_groups = {}
        self.buffered_daka_history = {}

        self.poster_tracker = [] # è®°å½•å·²å‘é€è¿‡çš„æµ·æŠ¥å†…å®¹
        self.buffered_poster_list = {} # è®°å½•grade1-grade5çš„æµ·æŠ¥åˆ—è¡¨
        self.poster_fetch_time = {} # è®°å½•ä¸Šæ¬¡è·å–grade1-grade5çš„æµ·æŠ¥çš„æ—¶é—´
        self.poster_thread_tids = None
        self.poster_queue = [] # è®°å½•éœ€è¦å‘é€çš„æµ·æŠ¥å†…å®¹
        self.random_session = random.randint(1, 5) # æµ·æŠ¥éšæœºé—´éš”

        self.tidal_tracker = [] # è®°å½•å¯èƒ½ä½¿ç”¨tidal_tokençš„ç¾¤ç»„share_key
        self.tidal_token_list = {} # è®°å½•tidal_token
        self.tidal_thread_tids = None
        self.tidal_token_queue = {} # è®°å½•å½“å‰éœ€è¦è·å–tidal_tokençš„ç¾¤ç»„share_key
        self.tidal_random_session = random.randint(1, 5) # tidal_tokenéšæœºé—´éš”

        self.rank_buffer = {} # key=1-7ï¼Œå¯¹åº”é’é“œåˆ°ç‹è€…
        self.rank_buffer_time = {} # key=1-7ï¼Œå¯¹åº”é’é“œåˆ°ç‹è€…

    # def getHeaders(self, token: str = '', note='') -> dict:
    #     '''è·å–è¯·æ±‚å¤´'''
    #     # TODO å®é™…ä¸Šä¸åŒåŸŸåè¯·æ±‚æœ‰ç»†å¾®å·®åˆ«ï¼Œè¿™é‡Œæš‚æ—¶åªä½¿ç”¨é»˜è®¤
    #     print(f"{note}:")
    #     if (not token):
    #         token = self.config.main_token

    #     current_headers = self.default_headers['default_headers_dict']

    #     if token not in self.hash_rmb:
    #         # å°†å“ˆå¸Œå€¼è½¬æ¢ä¸ºunsigned long longå€¼ï¼Œç„¶åå–åï¼Œå†è½¬æ¢ä¸º16è¿›åˆ¶å­—ç¬¦ä¸²
    #         hex_string = format(hash(token), '016x')
    #         self.hash_rmb[token] = {'hex_string': hex_string }

    #     current_cookie = self.default_cookie.copy()
    #     current_cookie['device_id'] = f'{self.hash_rmb[token]["hex_string"]}'
    #     current_cookie['access_token'] = token
    #     current_cookie['client_time'] = str(int(time.time()))
    #     current_headers['Cookie'] = ''
    #     for key, value in current_cookie.items():
    #         key = key.replace(";","%3B").replace("=","%3D")
    #         value = value.replace(";","%3B").replace("=","%3D")
    #         current_headers['Cookie'] += f'{key}={value};'
    #     # éœ€è¦è½¬ä¸ºstr
    #     print(current_headers['Cookie'])
    #     return current_headers


    def fetch(self, url: str, method: str = 'GET', headers: dict = {}, payload = None) -> httpx.Response:
        '''ç½‘ç»œè¯·æ±‚'''
        with httpx.Client() as client:
            if method.upper() == 'GET':
                response = client.get(url, headers=headers)
            elif method.upper() == 'POST':
                response = client.post(url, json=payload, headers=headers)
            else:
                raise ValueError('ä¸æ”¯æŒçš„è¯·æ±‚åè®®')
            return response

    def setGroupOnlyInviteCodeJoin(self, share_key: str, authorized_token: str) -> bool:
        '''åˆ‡æ¢å°ç­æ˜¯å¦ä»…å…è®¸é‚€è¯·ç åŠ å…¥'''
        headers = getHeaders(authorized_token)
        # https://group.baicizhan.com/group/set_only_public_key_join?shareKey=1alv4ldkkhcxyln6
        url = f"https://group.baicizhan.com/group/set_only_public_key_join?shareKey={share_key}"
        response = requests.post(url, headers=headers, json='{}', timeout=10)
        if response.json().get("code",0) != 1:
            logger.info(f"åˆ‡æ¢å°ç­æ˜¯å¦ä»…å…è®¸é‚€è¯·ç åŠ å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥{response.json()}")
            return False
        logger.info(f"åˆ‡æ¢å°ç­æ˜¯å¦ä»…å…è®¸é‚€è¯·ç åŠ å…¥æˆåŠŸ")
        return True

    async def asyncFetch(self, url: str, method: str = 'GET', headers: dict = {}, payload = None) -> httpx.Response:
        '''å¼‚æ­¥ç½‘ç»œè¯·æ±‚'''
        async with httpx.AsyncClient(verify=certifi.where()) as client:
            if method.upper() == 'GET':
                response = await client.get(url, headers=headers)
            elif method.upper() == 'POST':
                response = await client.post(url, json=payload, headers=headers)
            else:
                raise ValueError('ä¸æ”¯æŒçš„è¯·æ±‚åè®®')
            return response
        
    
    def joinGroup(self, share_key: str, access_token: str) -> int:
        '''åŠ å…¥å°ç­'''
        headers = getHeaders(access_token)
        headers["Content-Type"] = "application/json"
        # headers["Origin"] = "https://group.baicizhan.com"
        # headers["Referer"] = "https://group.baicizhan.com"
        json = {
            "shareKey": share_key,
            "source": 3
        }
        response = requests.post(f"https://group.baicizhan.com/group/join", headers=headers, json=json, timeout=10)
        data = response.json()
        if data.get("code",0) != 1:
            logger.info(f"åŠ å…¥å°ç­å¤±è´¥ï¼Œè¯·æ£€æŸ¥{data}")
            if data['message'] == 'è¯¥å°ç­å·²æ»¡å‘˜~':
                return 1
            return 2
        logger.info(f"åŠ å…¥å°ç­æˆåŠŸ")
        return 0

    def quitGroup(self, share_key: str, access_token: str) -> bool:
        '''é€€å‡ºå°ç­'''
        headers = getHeaders(access_token)
        headers['Content-Type'] = 'application/json; charset=UTF-8'
        response_json = requests.post(f'https://group.baicizhan.com/group/quit?shareKey={share_key}', data='{}', headers=headers).json()
        if response_json.get("code",0) != 1:
            logger.info(f"é€€å‡ºå°ç­å¤±è´¥ï¼Œè¯·æ£€æŸ¥{response_json}")
            return False
        logger.info(f"é€€å‡ºå°ç­æˆåŠŸ")
        return True

    def getOwnPosterState(self, poster: str) -> bool:
        '''æ£€æŸ¥è‡ªå·±çš„ä¸Šä¸€å¼ æµ·æŠ¥çš„é—´è·'''
        min_index = {}
        count = {}
        min_other_index = {}
        for grade in range(1, 6):
            min_index[grade] = -1
            min_other_index[grade] = -1
            count[grade] = 0
            if grade-1 not in self.buffered_poster_list:
                continue
            for i, post in enumerate(self.buffered_poster_list[grade-1]):
                if post['content'] == poster:
                    count[grade] += 1
                    if min_index[grade] == -1:
                        min_index[grade] = i
                if min_other_index[grade] == -1 and post['content'] in self.poster_tracker:
                    min_other_index[grade] = i
                # if min_index[grade] != -1 and min_other_index[grade] != -1:
                #     break
        # æ‰“åŒ…æˆmin_index/min_other_indexåˆ—è¡¨
        result = []
        for grade in range(1, 6):
            result.append(f"{min_index[grade]}/{min_other_index[grade]}:{count[grade]}")
        return result

    def getPosterState(self, grade: int, access_token: str, buffer : int = 15) -> bool:
        '''æ£€æŸ¥æµ·æŠ¥é—´éš”æ˜¯å¦è¶³å¤Ÿ'''

        last_poster_fetch_time = self.poster_fetch_time.get(grade-1, 0)
        if last_poster_fetch_time + buffer < time.time():
            get_url = 'https://group.baicizhan.com/group/get_recruitment_post_list?anchorId=0&direction=1'
            self.poster_fetch_time[grade-1] = time.time()
            headers = getHeaders(access_token)
            response = requests.get(get_url, headers=headers, timeout=10)
            self.buffered_poster_list[grade-1] = response.json().get('data')['recruitmentPostVoList']


        min_index = 1000000
        for content in self.poster_tracker: # ä¹‹å‰å‘è¿‡çš„æµ·æŠ¥å†…å®¹
            for i, post in enumerate(self.buffered_poster_list[grade-1]):
                if post['content'] == content:
                    min_index = min(min_index, i)
                    break
        
        return min_index
    
    def getPosterLog(self, group_id) -> dict:
        '''è·å–æµ·æŠ¥å‘é€æ—¥å¿—'''
        # è·å–ä»Šå¤©0ç‚¹æ—¶é—´å­—ç¬¦ä¸²
        record = {}
        today_0_time_str = datetime.now().strftime('%Y-%m-%d 00:00:00')
        for grade in range(1, 6):
            group_poster_cnt = 0
            min_index = 1000000
            i = 0
            if self.buffered_poster_list.get(grade-1) is None:
                record[grade] = {
                    'today_total_poster_cnt': 'æœªè·å–',
                    'group_poster_cnt': 0,
                    'min_index': 0,
                }
                continue
            for i, poster in enumerate(self.buffered_poster_list[grade-1]):
                if poster['createdAt'] < today_0_time_str:
                    break
                if poster['groupId'] == group_id:
                    group_poster_cnt += 1
                if min_index > i:
                    min_index = i
            record[grade] = {
                'today_total_poster_cnt': i,
                'group_poster_cnt': group_poster_cnt,
                'min_index': min_index,
            }
        return record

    def sendPosterThread(self, poster_token: list) -> bool:
        '''æµ·æŠ¥å‘é€çº¿ç¨‹'''
        time_delta = 30
        target_grade = 1
        total_grade = 5 # ä¸€å…±1234
        logger.info(f"\033[1;37mğŸ’– æµ·æŠ¥å‘é€çº¿ç¨‹å¯åŠ¨\033[0mç­‰å¾…{time_delta}s")
        time.sleep(time_delta) # ä¸ºäº†é˜²æ­¢ä¼˜å…ˆçº§ä½çš„ä»»åŠ¡å…ˆè¿›å…¥ç„¶åè¢«æŠ¢å ï¼Œè¿™é‡Œç­‰å¾…ä¸€æ®µæ—¶é—´
        try:
            while len(self.poster_queue) > 0:
                # poster_queueåˆ—è¡¨ä¸­åŒ…å«å­—å…¸ï¼Œå«æœ‰period, poster, group_id
                user_token = None
                for user in poster_token:
                    if user['grade'] == target_grade:
                        user_token = user['access_token']
                        break
                if user_token is not None:
                    min_index = self.getPosterState(target_grade, user_token) # åªæœ‰ç¬¬ä¸€ä¸ªç­çº§æ‰ä¼šåˆ·æ–°æµ·æŠ¥åˆ—è¡¨
                    # æŸ¥æ‰¾å½“å‰queueä¸­periodæœ€å°çš„
                    min_period = 1000000
                    target = None
                    for poster_dict in self.poster_queue:
                        period_ = poster_dict['period']
                        if period_ < min_index - self.random_session and period_ < min_period:
                            min_period = period_
                            target = poster_dict
                    if target is not None:
                        group_id = target['group_id']
                        group_name = target['group_name']
                        period_ = target['period']
                        poster = target['poster']
                        # å¦‚æœç°åœ¨æ˜¯8-11ç‚¹ï¼Œæˆ–14åˆ°16ç‚¹ï¼Œ21ç‚¹ä»¥åï¼Œåˆ™ä¸å‘é€æµ·æŠ¥
                        now_time = datetime.now().time()
                        no_poster_time = [8, 9, 10, 11, 14, 15, 16, 21, 22, 23]
                        if now_time.hour in no_poster_time:
                            logger.info(f"\033[1;37mğŸ•’ ç°åœ¨æ˜¯{now_time}(in {no_poster_time})ï¼Œä¸æ˜¯å‘é€æµ·æŠ¥çš„æ—¶é—´\033[0m")
                        elif self.sendPoster(group_id, target_grade, user_token, poster):
                            logger.info(f"\033[1;37mğŸ’– æµ·æŠ¥{target_grade}åŒºé—´éš”{min_index}-{self.random_session}æ‰§è¡Œ{group_name}({period_})æˆåŠŸ\033[0m")
                        else:
                            logger.info(f"\033[1;37mâš ï¸ æµ·æŠ¥{target_grade}åŒºé—´éš”{min_index}-{self.random_session}æ‰§è¡Œ{group_name}({period_})å¤±è´¥\033[0m")
                        self.random_session = random.randint(1, 5) # éšæœºé—´éš”
                    else:
                        logger.info(f"\033[1;37mæµ·æŠ¥{target_grade}åŒºé—´éš”{min_index}-{self.random_session}æ— å¯å‘é€å†…å®¹\033[0m")
                else:
                    logger.info(f"\033[1;37mæµ·æŠ¥{target_grade}åŒºæ— å¯ç”¨ä»¤ç‰Œ\033[0m")
                waiting_group_name = []
                for poster_dict in self.poster_queue:
                    waiting_group_name.append(poster_dict['group_name'])
                logger.info(f'ç­‰å¾…é˜Ÿåˆ—ï¼š{waiting_group_name}')
                target_grade = (target_grade + 1) % total_grade + 1
                time.sleep(time_delta)
        finally:
            logger.info(f"\033[1;37mğŸ“ æµ·æŠ¥å‘é€çº¿ç¨‹ç»“æŸ\033[0m")
            self.poster_thread_tids = None
    
    def joinPosterQueue(self, period: int, poster: str, group_id: str, group_name: str, poster_token: list) -> bool:
        '''åŠ å…¥æµ·æŠ¥é˜Ÿåˆ—ï¼Œposter_tokenç”±filterä¼ å…¥å’Œç®¡ç†'''
        poster_dict = {
            'period': period,
            'poster': poster,
            'group_id': group_id,
            'group_name': group_name,
        }
        if poster_dict not in self.poster_queue:
            self.poster_queue.append(poster_dict)
            if self.poster_thread_tids is None:
                self.poster_thread_tids = threading.Thread(target=self.sendPosterThread, args=(poster_token,))
                self.poster_thread_tids.start()
            return True
        return False # å·²åœ¨é˜Ÿåˆ—ä¸­

    def quitPosterQueue(self, group_id: str) -> bool:
        for poster_dict in self.poster_queue:
            if poster_dict['group_id'] == group_id:
                self.poster_queue.remove(poster_dict)
                return True
        return False # ä¸åœ¨é˜Ÿåˆ—ä¸­
    
    def inPosterQueue(self, group_id: str) -> bool:
        for poster_dict in self.poster_queue:
            if poster_dict['group_id'] == group_id:
                return True
        return False # ä¸åœ¨é˜Ÿåˆ—ä¸­


    def setPosterTracker(self, content: str) -> None:
        '''è®°å½•å·²å‘é€è¿‡çš„æµ·æŠ¥å†…å®¹ï¼Œæ¯ä¸ªfilterä¸€å¯åŠ¨å°±ä¼šè°ƒç”¨'''
        if content not in self.poster_tracker:
            self.poster_tracker.append(content)

    def sendPoster(self, group_id: str, grade: int, access_token: str, poster: str) -> bool:
        '''å‘é€æµ·æŠ¥'''
        get_url = 'https://group.baicizhan.com/group/get_recruitment_style_info'
        headers = getHeaders(access_token)
        response = requests.get(get_url, headers=headers, timeout=10)
        time.sleep(1)
        style_info = response.json().get('data')['list']
        style = -1
        for post in style_info:
            if post['credit'] == 0 and post['count'] > 0: # æŸ¥è¯¢è¿˜æœ‰æ²¡æœ‰å…è´¹çš„æµ·æŠ¥
                style = post['id']
                break
        for post in style_info:
            if post['count'] > 0:
                style = post['id']
                break
        if style == -1:
            logger.info(f"æ²¡æœ‰å¯ç”¨çš„æµ·æŠ¥æ ·å¼")
            return False
        
        post_url = 'https://group.baicizhan.com/group/publish_post'
        headers = getHeaders(access_token)
        headers["Content-Type"] = "application/json"
        headers["Origin"] = "https://group.baicizhan.com"
        headers["Referer"] = "https://group.baicizhan.com/wanted_board/create"
        payload = {
            "content": poster,
            "groupId": group_id,
            "style": style,
            "type": 1,
        }
        response = requests.post(post_url, headers=headers, json=payload, timeout=10)
        data = response.json()
        if data.get("code",0) != 1:
            logger.info(f"å‘é€æµ·æŠ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥{response.json()}")
            return False
        if data['data']['state'] == 2:
            logger.info('å·²è¿‡å®¡')
            self.getPosterState(grade, access_token, buffer=1) # æ›´æ–°æµ·æŠ¥åˆ—è¡¨
            return True
        else:
            logger.info('â–² æµ·æŠ¥å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥')
            return False
        
    def getRank(self, group_id: int, access_token: str, rank: int, buffer_time = 60) -> int:
        # è·å–å°ç­æ’å
        # https://group.baicizhan.com/group/get_group_rank?rank=7
        group_id = int(group_id)
        if self.rank_buffer_time.get(rank) is None or self.rank_buffer_time[rank] + buffer_time < time.time():
            headers = getHeaders(access_token)
            response = requests.get(f"https://group.baicizhan.com/group/get_group_rank?rank={rank}", headers=headers, timeout=10)
            self.rank_buffer_time[rank] = time.time()
            self.rank_buffer[rank] = response.json().get('data')['list']
        for i, group in enumerate(self.rank_buffer[rank]):
            if group['groupId'] == group_id:
                return i + 1
        return 1001

    def tidalTokenThread(self, tidal_token: list) -> None:
        # return
        # print(self.tidal_thread_tids)
        # if self.tidal_thread_tids is not None:
        #     return
        def update_tidal_token_class_list(user):
            # æ›´æ–°tidal_token_class_list
            # print(f'è¯·æ±‚token:{user["access_token"]}')
            j, a, g = self.getUserLimit(user['access_token'])
            user_groups_info = self.getUserGroupInfo('0', user['access_token']) # uniqueIdå¡«0æ—¶è·å–è‡ªèº«
            user['join_groups'] = []
            user['join_groups_share_keys'] = []
            user['join_groups_days'] = []
            user['join_groups_names'] = []
            user['current_tidal_group_count'] = 0
            user['join_limit'], user['auth_limit'], user['grade'] = j, a, g
            for info in user_groups_info:
                user['join_groups'].append(str(info['id']))
                user['join_groups_share_keys'].append(info['share_key'])
                user['join_groups_days'].append(info['join_days'])
                user['join_groups_names'].append(info['name'])
                if str(info['id']) in self.tidal_tracker and info['join_days'] < 3:
                    user['current_tidal_group_count'] = user.get('current_tidal_group_count', 0) + 1
        
        time_delta = 10
        current_share_key = ''
        current_group_id = ''
        current_group_name = ''
        all_tidal_token_cleared = False
        try:

            while not all_tidal_token_cleared:
                all_tidal_token_cleared = True
                min_tidal_index = 1000000 # åŠ å…¥æ½®æ±ä»¤ç‰Œçš„ä¼˜å…ˆçº§
                current_share_key = ''
                current_group_id = ''
                current_group_name = ''
                current_preserve_rank = False
                vacancy_log = {}
                for _, group in self.tidal_token_queue.items():
                    name = group['group_name']
                    vacancy = group['tidal_vacancy']
                    preserve_rank = group['preserve_rank']
                    vacancy_log[name] = f'{vacancy}'
                    if preserve_rank:
                        vacancy_log[name] += '+'
                    if group['tidal_index'] < min_tidal_index and (vacancy > 6 or (preserve_rank and vacancy > 0)): # ä¿æŒäººæ•°åœ¨max-6
                        min_tidal_index = group['tidal_index']
                        current_share_key = group['share_key']
                        current_group_name = name
                        current_group_id = group['group_id']
                        current_preserve_rank = preserve_rank
                if current_group_id != '':
                    logger.info(f"ğŸŒŠ ä¼˜å…ˆçº§æœ€é«˜çš„æ½®æ±ç»„[{current_share_key},{current_group_id}]{current_group_name}(-{self.tidal_token_queue[current_group_id]['tidal_vacancy']})")
                    all_tidal_token_cleared = False
                logger.info(f"æ½®æ±é˜Ÿåˆ—ï¼š{vacancy_log}")

                for user in tidal_token:
                    user_name = user['name']
                    user_grade = user['grade']


                    # logger.info(f"å¼€å§‹æ£€æŸ¥æ½®æ±ä»¤ç‰Œ[{user_name}]")
                    if user.get('join_groups', None) is None:
                        update_tidal_token_class_list(user)
                        logger.info(f"ğŸ¥° è·å–äº†{user_grade}{user_name}ç­çº§åˆ—è¡¨")
                        all_tidal_token_cleared = False 
                        break

                    groups = user['join_groups']
                    join_limit = user['join_limit'] # é»˜è®¤3
                    tidal_group_limit = user.get('tidal_group_limit', 6) # é»˜è®¤6
                    current_tidal_group_count = user['current_tidal_group_count']
                    if current_tidal_group_count > 0:
                        all_tidal_token_cleared = False # æœ‰æ½®æ±å°ç­ï¼Œä¸æ¸…ç©ºé˜Ÿåˆ—
                    
                    # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰åŠ å…¥å¹¶ä¸”å·²ç»ä¸éœ€è¦çš„æ½®æ±å°ç­
                    checked = 0
                    user_share_key = user['join_groups_share_keys']
                    user_join_days = user['join_groups_days']
                    user_group_name = user['join_groups_names']
                    for i, group_id in enumerate(groups):
                        share_key = user_share_key[i]
                        join_days = user_join_days[i]
                        group_name = user_group_name[i]
                        # print(group_name, group_id, type(group_id))
                        # print(group_id in self.tidal_tracker, self.tidal_token_queue)
                        # print(self.tidal_tracker)

                        if group_id not in self.tidal_tracker or join_days >= 3 or self.tidal_token_queue.get(group_id, None) is None:
                            # logger.info(f"æ‰¾åˆ°{user_name}åŠ å…¥äº†{group_name}({group_id}) {join_days}å¤©ï¼Œä¸ç¬¦åˆæ½®æ±ç»„ï¼Œè·³è¿‡")
                            continue # ä¸æ˜¯æ½®æ±å°ç­ æˆ– åŠ å…¥æ—¶é—´è¶…è¿‡3å¤©(ä¸æ˜¯æ½®æ±ä»¤ç‰Œ) æˆ– æ½®æ±å°ç­ä¿¡æ¯æœªç»™å‡º
                        vacancy = self.tidal_token_queue[group_id]['tidal_vacancy']
                        preserve_rank = self.tidal_token_queue[group_id]['preserve_rank']
                        if group_id in self.tidal_tracker and (vacancy < 6 and not preserve_rank): # ä¿æŒäººæ•°åœ¨max-6
                            update_tidal_token_class_list(user)
                            if group_id not in user['join_groups']:
                                continue
                            # logger.info(f'æ‰¾åˆ°{user_name}åŠ å…¥äº†{group_name}({group_id}) {join_days}å¤©ï¼Œé€€å‡º')
                            if self.quitGroup(share_key, user['access_token']):
                                logger.info(f"[{group_name}]ğŸŒŠ \033[1;35mç§»é™¤tidal_token{user_grade}{user_name}ï¼ŒåŠ å…¥æ—¶é—´{join_days}(<3)å¤©ï¼Œè¿˜å‰©{user['current_tidal_group_count'] - 1}ä¸ª\033[0m(60s)")
                                self.tidal_token_queue[group_id]['tidal_vacancy'] += 1
                            else:
                                logger.warning(f"[{group_name}]é€€å‡ºæ½®æ±ä»¤ç‰Œ{user_grade}{user_name}å¤±è´¥(60s)")
                            checked = 1
                            break # ä¿è¯æ¯ä¸ªè´¦å·æ¯ä¸€è½®åªè¯·æ±‚ä¸€æ¬¡

                    if checked == 0:
                        # logger.info(f"[{user_name}]æ²¡æœ‰åŠ å…¥æˆ–ç§»é™¤tidal_groupså®Œæ¯•")
                        ...
                    else:
                        continue

                    # ä»ç°æœ‰çš„æ‰¾ï¼Œå¦‚æœæ²¡æœ‰ï¼Œæ‰¾ä¸ªæ–°çš„
                    if current_share_key == '':
                        # logger.info(f"æ½®æ±é˜Ÿåˆ—ä¸ºç©º")
                        continue
                    if len(groups) < join_limit and current_group_id not in groups and current_tidal_group_count < tidal_group_limit:
                        # è¿˜æœ‰è‡³å°‘2ä¸ªç©ºä½ å¹¶ä¸” è¯¥ä»¤ç‰Œæ²¡åŠ å…¥è¯¥ç­çº§ å¹¶ä¸” è¿˜æ²¡è¾¾åˆ°è‡ªå®šä¹‰é™åˆ¶ï¼Œåˆ™åŠ å…¥
                        result_status = self.joinGroup(current_share_key, user['access_token'])
                        if result_status == 0:
                            logger.info(f"[{current_group_name}]ğŸŒŠ \033[1;33måŠ å…¥æ½®æ±ä»¤ç‰Œ{user_grade}{user_name}æˆåŠŸ(ç°{len(groups) + 1}/{join_limit} æ½®æ±{current_tidal_group_count + 1}/{tidal_group_limit})\033[0m")
                            self.tidal_token_queue[current_group_id]['tidal_vacancy'] -= 1
                        elif result_status == 1:# å¯èƒ½åœ¨é—´éš”ä¸­ï¼Œè¯¥å°ç­å·²ç»æ»¡å‘˜
                            self.tidal_token_queue[current_group_id]['tidal_vacancy'] = 0
                        else:
                            logger.warning(f"[{current_group_name}]åŠ å…¥æ½®æ±ä»¤ç‰Œ{user_grade}{user_name}å¤±è´¥(60s)")
                        update_tidal_token_class_list(user)
                        break
                if not current_preserve_rank:
                    time.sleep(time_delta)
                else:
                    time.sleep(time_delta / 2)
        except Exception as e:
            logger.error(f"tidalTokenThreadå‡ºç°å¼‚å¸¸ï¼š{e}")
        finally:
            logger.info(f"ğŸ§­ æ½®æ±ä»¤ç‰Œé˜Ÿåˆ—ä¸ºç©ºï¼Œé€€å‡º")
            self.tidal_thread_tids = None
                    
    def joinTidalToken(self, share_key: str, group_name: str, tidal_index: int, group_id: str, tidal_vacancy: int, tidal_token: list, preserve_rank: bool) -> bool:
        '''åŠ å…¥æ½®æ±ä»¤ç‰Œã€‚æ½®æ±ä»¤ç‰Œä½¿ç”¨æŒ‡å—ï¼šæ½®æ±ä»¤ç‰Œä¼šä¿æŒäººæ•°åœ¨194ï¼Œä¸»çº¿ç¨‹ä¼šåœ¨198é€€å‡ºï¼Œå› æ­¤å†²æ¦œç±»ç­–ç•¥ä¿ç•™äººæ•°åº”å°äº194ï¼Œç­›é€‰ç±»åº”å¤§äº194'''
        group_id = str(group_id)# pythonå®å‚å¯ä»¥æ”¹å˜å½¢å‚çš„ç±»å‹çœŸçš„æ˜¯å¾ˆç³Ÿç³•
        if self.tidal_thread_tids is None:
            self.tidal_thread_tids = threading.Thread(target=self.tidalTokenThread, args=(tidal_token,))
            self.tidal_thread_tids.start()
        if group_id not in self.tidal_token_queue:
            self.tidal_token_queue[group_id] = {'share_key': share_key, 'group_name': group_name, 'tidal_index': tidal_index, 'group_id': group_id, 'tidal_vacancy': tidal_vacancy, 'preserve_rank': preserve_rank}
            return True
        else:
            self.tidal_token_queue[group_id] = {'share_key': share_key, 'group_name': group_name, 'tidal_index': tidal_index, 'group_id': group_id, 'tidal_vacancy': tidal_vacancy, 'preserve_rank': preserve_rank}
            return False # å·²åœ¨é˜Ÿåˆ—ä¸­
    
    def quitTidalToken(self, group_id: str) -> bool:
        group_id = str(group_id)
        if group_id in self.tidal_token_queue:
            self.tidal_token_queue.pop(group_id)
            return True
        return False

    def inTidalTokenQueue(self, group_id: str) -> bool:
        group_id = str(group_id)
        if group_id in self.tidal_token_queue and self.tidal_token_queue[group_id]['tidal_vacancy'] > 6: # ä¿æŒäººæ•°åœ¨max-6
            return True
        return False
        
    def setTidalTokenTracker(self, group_id: str) -> None:
        '''è®¾ç½®å¯èƒ½ä¼šä½¿ç”¨tidal_tokençš„ç¾¤ç»„'''
        group_id = str(group_id)
        if group_id not in self.tidal_tracker:
            self.tidal_tracker.append(group_id)
            return True
        else:
            return False


    # ç§»é™¤æˆå‘˜
    def removeMembers(self, user_id: list, share_key: str, access_token: str) -> bool:
        
        url = f"{self.remove_members_url}?shareKey={share_key}"
        # æš‚ä¸ç¡®å®šurlæ ¼å¼ï¼Œç¨åæµ‹è¯•
        headers = getHeaders(access_token)
        headers["Access-Control-Request-Method"] = "POST"
        headers["Access-Control-Request-Headers"] = "content-type"
        headers["Origin"] = "https://activity.baicizhan.com"
        headers["Referer"] = "https://activity.baicizhan.com"
        
        response = requests.options(url, headers = headers, timeout=10)# å…ˆå‘ä¸€ä¸ªOPTIONSæµ‹è·¨åŸŸPOST
        json =  {
            "memberIds": user_id,
            "shareKey": share_key,
        }

        headers = getHeaders(access_token)
        headers["Content-Type"] = "application/json"
        headers["Origin"] = "https://activity.baicizhan.com"
        headers["Referer"] = "https://activity.baicizhan.com"
        response = requests.post(url, headers = headers, json = json, timeout=10)
        # print(f"æµ‹è¯•ï¼åˆ é™¤ï¼š{json}")
        if response.json().get("code",0) != 1:
            msg = response.json().get("message","")
            if "ä¸åœ¨å°ç­ä¸­" in msg:
                logger.info(f"åˆ é™¤çš„äººå·²ç»ä¸åœ¨å°ç­ä¸­")
                return False
            elif "æ²¡æœ‰æƒé™" == msg:
                logger.info(f"\033[1;31m{share_key}.{access_token}æ²¡æœ‰æƒé™\033[0måˆ é™¤ï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†magic_proxyå¿˜è®°å…³é—­ã€‚æš‚åœè¿è¡Œ30s")
                time.sleep(30)
                return False
            logger.info(f"remove{json}å‡ºç°å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥")
            return False
        logger.info(f"åˆ é™¤æˆåŠŸ")
        return True
            # 2024.2.23 15:39 æˆåŠŸç¬¬ä¸€æ¬¡
            

    def getInfo(self) -> dict:
        '''è·å–è¿è¡Œä¿¡æ¯'''
        main_info = self.getOwnInfo(self.config.main_token)
        token_valid = False
        if main_info['uid']:
            token_valid = True
        return {
            'token_valid': token_valid,
            'uid': main_info['uid'],
            'name': main_info['name'],
        }

    def getOwnInfo(self, token: str) -> dict:
        '''ã€æˆ‘çš„æ ¡ç‰Œã€‘è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯'''
        data = {
            'uid': None,
            'name': None,
        }
        headers = getHeaders(token)
        response = requests.get(self.own_info_url, headers=headers, timeout=10)
        if response.status_code != 200 or response.json().get('code') != 1:
            logger.warning(f'ä½¿ç”¨tokenè·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥!\n{response.text}')
        user_info = response.json().get('data')
        if user_info is None:
            data['uid'] = 'None'
            data['name'] = 'None'
            return data
        data['uid'] = user_info['mine']['uniqueId']
        data['name'] = user_info['mine']['name']
        return data
        
    def getUserInfo(self, user_id: str = None) -> dict | None:
        '''ã€ç”¨æˆ·æ ¡ç‰Œã€‘è·å–ç”¨æˆ·åã€åŒæ¡Œå¤©æ•°ã€æ˜¯å¦é è°±å¤´åƒæ¡†'''
        # è·å–åŒæ¡Œä¿¡æ¯
        if not user_id:
            return
        url = f'{self.user_deskmate_url}?uniqueId={user_id}'
        headers = getHeaders(self.config.main_token)
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200 or response.json().get('code') != 1:
            msg = f'è·å–åŒæ¡Œå¤±è´¥! ç”¨æˆ·ä¸å­˜åœ¨æˆ–ä¸»æˆæƒä»¤ç‰Œæ— æ•ˆ'
            logger.error(f'{msg}\n{response.text}')
            raise Exception(msg)
        user_info = {}
        user_info['unique_id'] = user_id
        user_info['name'] = response.json()['data']['userInfo']['name']
        user_info['deskmate_days'] = response.json()['data']['deskmateDays']
        response = requests.get(f'{self.user_card_info}?uniqueId={user_id}', headers=headers, timeout=10)
        user_info['max_daka_days'] = response.json()['data']['dakaDays']
        # è·å–å°é˜Ÿä¿¡æ¯
        url = f'{self.user_team_url}?bcz_id={user_id}'
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200 or response.json().get('code') != 1:
            logger.warning(f'è·å–å°é˜Ÿä¿¡æ¯å¤±è´¥!\n{response.text}')
        team_info = response.json().get('data').get('members')
        if team_info is None or len(team_info) == 0:
            # æœªåŠ å…¥å°é˜Ÿ
            user_info['dependable_frame'] = 4
        else:
            for member in team_info:
                if member['bczId'] == user_id:
                    user_info['dependable_frame'] = member['tag']
                    # 3é è°±ï¼Œ0ä¸é è°±ï¼Œ1èŒæ–°
        if user_info.get('dependable_frame') is None:
            user_info['dependable_frame'] = 4
        return user_info
    
    def getUserLimit(self, access_token: str = ''):
        '''è·å–ã€ç”¨æˆ·æ ¡ç‰Œã€‘åŠ å…¥ä¸Šé™ã€æˆæƒä¸Šé™ã€çº§ç»„'''
        if access_token == '':
            access_token = self.config.main_token
        headers = getHeaders(access_token)
        response = requests.get('https://group.baicizhan.com/group/get_group_user_info', headers=headers) # æˆ‘çš„å°ç­
        data = response.json().get('data')
        if not data:
            return 0
        return data["groupLimiteNumber"], data["groupAuthorizationLimiteNumber"], data['grade']


    def getUserGroupInfo(self, user_id: str = None, access_token: str = '') -> list[dict]:
        '''è·å–ã€æˆ‘çš„å°ç­ã€‘ä¿¡æ¯own_groups'''
        if not user_id:
            return {}
        if access_token == '':
            access_token = self.config.main_token
        url = f'{self.group_list_url}?uniqueId={user_id}'
        headers = getHeaders(access_token)
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200 or response.json().get('code') != 1:
            msg = f'è·å–æˆ‘çš„å°ç­ä¿¡æ¯å¤±è´¥! ç”¨æˆ·ä¸å­˜åœ¨æˆ–ä¸»æˆæƒä»¤ç‰Œæ— æ•ˆ'
            logger.error(f'{msg}\n{response.text}')
            raise Exception(msg)
        group_info = response.json().get('data')
        group_list = group_info.get('list') if group_info else []
        groups = []
        data_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())
        for group in group_list:
            group_id = group['id']
            group_name = group['name'] if group['name'] else ''
            group_name = re.sub(self.invalid_pattern, '', group_name)
            introduction = group['introduction'] if group['introduction'] else ''
            introduction = re.sub(self.invalid_pattern, '', introduction)
            avatar_frame = group['avatarFrame']['frame'] if group.get('avatarFrame') else ''
            groups.append({
                'id': group_id,
                'name': group_name,
                'share_key': group['shareKey'],
                'introduction': introduction,
                'leader': group['leader'],
                'member_count': group['memberCount'],
                'count_limit': group['countLimit'],
                'today_daka_count': group['todayDakaCount'],
                'finishing_rate': group['finishingRate'],
                'created_time': group['createdTime'],
                'rank': group['rank'],
                'type': group['type'],
                'avatar': group['avatar'],
                'avatar_frame': avatar_frame,
                'data_time': data_time,
                'join_days': group['joinDays'],
                'unique_id': user_id,
                'today_date': datetime.now().strftime('%Y-%m-%d'),
            })
        return groups

    def getGroupInfo(self, share_key: str, auth_token: str = '', buffered_time: int = 1) -> dict:
        '''è·å–ã€ç­å†…ä¸»é¡µã€‘ä¿¡æ¯group/information'''
        if auth_token == '':
            auth_token = self.config.main_token
        buffer_data = self.buffered_groups.get(share_key)
        buffer_time = buffer_data.get('data_time') if buffer_data else None
        # logger.info(f'groupInfo: è·å–åˆ°ç¼“å­˜æ—¶é—´{buffer_time}')
        # å¦‚æœå½“å‰æ—¶é—´æ¯”self.data_timeæ™šå°‘äºbuffered_timeç§’ï¼Œåˆ™ç›´æ¥è¿”å›ç¼“å­˜æ•°æ®
        if buffer_time and (datetime.now() - datetime.strptime(buffer_time, '%Y-%m-%d %H:%M:%S')).seconds < buffered_time:
            logger.info(f'ä½¿ç”¨ç¼“å­˜æ•°æ®')
            return self.buffered_groups.get(share_key)
        
        
        url = f'{self.group_detail_url}?shareKey={share_key}'
        headers = getHeaders(self.config.main_token)
        main_response = requests.get(url, headers=headers, timeout=10)
        if main_response.status_code != 200 or main_response.json().get('code') != 1:
            msg = f'ä½¿ç”¨ä¸»æˆæƒä»¤ç‰Œè·å–åˆ†äº«ç ä¸º{share_key}çš„å°ç­ä¿¡æ¯å¤±è´¥! å°ç­ä¸å­˜åœ¨æˆ–ä¸»æˆæƒä»¤ç‰Œæ— æ•ˆ'
            logger.warning(f'{msg}\n{main_response.text}')
            # raise Exception(msg)
            return {
                'share_key': share_key,
                'exception': main_response.text,
            }
        main_data = main_response.json()['data']
        auth_data = {}
        if auth_token:
            headers = getHeaders(auth_token)
            auth_response = requests.get(url, headers=headers, timeout=10)
            if auth_response.status_code != 200 or main_response.json().get('code') != 1:
                msg = f'ä½¿ç”¨å†…éƒ¨æˆæƒä»¤ç‰Œè·å–åˆ†äº«ç ä¸º{share_key}çš„å°ç­ä¿¡æ¯å¤±è´¥! å°ç­ä¸å­˜åœ¨æˆ–å†…éƒ¨æˆæƒä»¤ç‰Œæ— æ•ˆ'
                logger.warning(f'{msg}\n{main_response.text}')
            auth_data = auth_response.json()['data']
            
        return self.parseGroupInfo(main_data, auth_data)


    def getGroupsInfo(self, groups: list[dict], with_nickname: bool = True, only_favorite: bool = False) -> list:
        '''ã€å¤šä¸ª ç­å†…ä¸»é¡µã€‘æ‰¹é‡è·å–å°ç­ä¿¡æ¯'''
        async def asyncGroupsInfo(groups: list[dict]) -> list[dict]:
            group_fetch_list = []
            for group in groups:
                if only_favorite and not group.get('favorite'):
                    continue
                group_fetch_list.append({
                    'share_key': group["share_key"],
                    'auth_token': group['auth_token'],
                })
            main_headers = getHeaders(self.config.main_token)
            main_future = asyncio.gather(*[
                self.asyncFetch(f'{self.group_detail_url}?shareKey={i["share_key"]}', headers=main_headers)
                for i in group_fetch_list
            ])
            # auth_response_list = []
            rank_response_list = []
            if with_nickname:
                # åˆ©ç”¨ç­å†…æ’è¡Œæ¦œå³å¯è·å–å°ç­æ˜µç§°ï¼Œå› æ­¤æ³¨é‡Šè¯¥æ®µ
                # auth_future = asyncio.gather(*[
                #     self.asyncFetch(i['url'], headers=getHeaders(i['auth_token']))
                #     for i in group_fetch_list if i['auth_token']
                # ] )
                # auth_response_list: list[httpx.Response] = await auth_future
                rank_future = asyncio.gather(*[
                    self.asyncFetch(f'{self.get_week_rank_url}?shareKey={i["share_key"]}', headers=main_headers)
                    for i in group_fetch_list
                ] )
                rank_response_list: list[httpx.Response] = await rank_future
            main_response_list: list[httpx.Response] = await main_future
            groups_result = []
            for i, response in enumerate(main_response_list):
                if response.status_code != 200 or response.json().get('code') != 1:
                    msg = f'è·å–å°ç­{groups[i]["name"]}çš„ä¿¡æ¯å¤±è´¥! å°ç­ä¸å­˜åœ¨æˆ–ä¸»æˆæƒä»¤ç‰Œæ— æ•ˆ'
                    logger.warning(f'{msg}\n{response.text}')
                main_data: dict = main_response_list[i].json().get('data', '')
                auth_data: dict = '' if groups[i]['auth_token'] else None
                rank_data: dict = '' if groups[i]['auth_token'] else None
                if main_data and with_nickname:
                    # åˆ©ç”¨ç­å†…æ’è¡Œæ¦œå³å¯è·å–å°ç­æ˜µç§°ï¼Œå› æ­¤æ³¨é‡Šè¯¥æ®µ
                    # for auth_response in auth_response_list:
                    #     if auth_response.status_code == 200 or auth_response.json().get('code') == 1:
                    #         share_key = main_data.get('groupInfo').get('shareKey')
                    #         temp = auth_response.json().get('data', '')
                    #         if temp and temp.get('groupInfo').get('shareKey') == share_key:
                    #             auth_data = temp
                    rank_response = rank_response_list[i]
                    if rank_response.status_code == 200 or rank_response.json().get('code') == 1:
                        rank_data = rank_response.json().get('data', '')
                elif not main_data:
                    main_data = {
                        'share_key': groups[i]['share_key'],
                        'exception': main_response_list[i].text,
                        'valid': 2,
                    }
                groups_result.append(self.parseGroupInfo(
                    main_data,
                    auth_data,
                    rank_data
                ))

            return groups_result
        return asyncio.run(asyncGroupsInfo(groups))

    def parseGroupInfo(self, main_data: dict, auth_data: dict = {}, rank_data: dict = {}) -> dict:
        '''è¯·è°ƒç”¨ getGroupInfo æˆ– getGroupsInfoï¼Œæ­¤å‡½æ•°ä»…å†…éƒ¨è°ƒç”¨ï¼Œä»…ç”¨äºä¿¡æ¯è§£æ'''
        if not main_data or 'exception' in main_data:
            return main_data
        data_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())
        group_info = main_data.get('groupInfo') if main_data else []
        group_id = group_info['id']
        group_name = re.sub(self.invalid_pattern, '', group_info['name']) if group_info['name'] else ''
        introduction = re.sub(self.invalid_pattern, '', group_info['introduction']) if group_info['introduction'] else ''
        notice = re.sub(self.invalid_pattern, '', group_info['notice']) if group_info['notice'] else ''
        avatar_frame = group_info['avatarFrame']['frame'] if group_info.get('avatarFrame') else ''
        group = {
            'id': group_id,
            'name': group_name,
            'share_key': group_info['shareKey'],
            'introduction': introduction,
            'leader': '',
            'leader_id': '',
            'member_count': group_info['memberCount'],
            'count_limit': group_info['countLimit'],
            'today_daka_count': group_info['todayDakaCount'],
            'finishing_rate': group_info['finishingRate'],
            'created_time': group_info['createdTime'],
            'rank': group_info['rank'],
            'type': group_info['type'],
            'avatar': group_info['avatar'],
            'avatar_frame': avatar_frame,
            'notice': notice,
            'data_time': data_time,
            'valid': 1,
            'only_public_key_join': group_info['onlyPublicKeyJoin'],
        }

        today_date = main_data.get('todayDate') if main_data else ''
        today_daka_count = 0
        main_member_list = main_data.get('members', []) if main_data else []
        members = []
        for member in main_member_list:
            member_id = member['uniqueId']
            nickname = re.sub(self.invalid_pattern, '', member['nickname'])
            completed_time = ''
            if member['completedTime']:
                today_daka_count += 1
                completed_time = time.strftime('%H:%M:%S', time.localtime(member['completedTime']))
            members.append({
                'id': member_id,
                'member_id': member['id'],
                'group_id': group_id,
                'group_name': group_name,
                'nickname': nickname,
                'group_nickname': '',
                'avatar': member['avatar'],
                'book_name': member['bookName'],
                'today_word_count': member['todayWordCount'],
                'completed_times': member['completedTimes'],
                'completed_time': completed_time,
                'completed_time_stamp': member['completedTime'],
                'duration_days': member['durationDays'],
                'today_study_cheat': 'æ˜¯' if member['todayStudyCheat'] else 'å¦',
                'today_date': today_date,
                'data_time': data_time,
            })
            if member['leader']:
                group['leader'] = nickname
                group['leader_id'] = member_id

        # åˆ©ç”¨ç­å†…æ’è¡Œæ¦œå³å¯è·å–å°ç­æ˜µç§°ï¼Œå› æ­¤æ³¨é‡Šè¯¥æ®µ
        # if auth_data:
        #     auth_member_list = auth_data.get('members') if auth_data else []
        #     for member in auth_member_list:
        #         member_id = member['uniqueId']
        #         nickname = re.sub(self.invalid_pattern, '', member['nickname'])
        #         for member_info in members:
        #             if member_id == member_info['id'] and member_info['nickname'] != nickname:
        #                 member_info['group_nickname'] = member['nickname']
        # elif auth_data == '':
        #     group['token_invalid'] = True

        if rank_data:
            rank_member_list = rank_data.get('list') if rank_data else []
            for member in rank_member_list:
                member_id = member['uniqueId']
                nickname = re.sub(self.invalid_pattern, '', member['nickname'])
                for member_info in members:
                    if member_id == member_info['id'] and member_info['nickname'] != nickname:
                        member_info['group_nickname'] = nickname
        else:
            group['token_invalid'] = True

        if today_daka_count != 0:
            group['today_daka_count'] = today_daka_count
        group['members'] = members
        
        self.buffered_groups[group_info['shareKey']] = group
        return self.buffered_groups.get(group_info['shareKey'])

    def getGroupDakaHistory(self, share_key: str, parsed: bool = False, buffered_time: int = 1) -> dict:
        '''è·å–å°ç­æˆå‘˜å†å²æ‰“å¡ä¿¡æ¯'''
        if parsed:
            # æš‚å®šåªæœ‰åˆ†ç¦»çš„è®°å½•æ¨¡å¼
            buffer_data = self.buffered_daka_history.get(share_key)
            buffer_time = buffer_data.get('data_time') if buffer_data else None
            # logger.info(f'dakaHistory: è·å–åˆ°ç¼“å­˜æ—¶é—´{buffer_time}')
            
            # å¦‚æœå½“å‰æ—¶é—´æ¯”self.data_timeæ™šå°‘äºbuffered_timeç§’ï¼Œåˆ™ç›´æ¥è¿”å›ç¼“å­˜æ•°æ®
            if buffer_time and (datetime.now() - datetime.strptime(buffer_time, '%Y-%m-%d %H:%M:%S')).seconds < buffered_time:
                logger.info(f'ä½¿ç”¨ç¼“å­˜æ•°æ®')
                return self.buffered_daka_history.get(share_key)

        url = f'{self.get_week_rank_url}?shareKey={share_key}'
        headers = getHeaders(self.config.main_token)
        week_response = requests.get(f'{url}&week=1', headers=headers, timeout=10)
        if week_response.status_code != 200 or week_response.json().get('code') != 1:
            msg = f'è·å–åˆ†äº«ç ä¸º{share_key}çš„å°ç­æˆå‘˜å†å²æ‰“å¡ä¿¡æ¯å¤±è´¥! å°ç­ä¸å­˜åœ¨æˆ–ä¸»æˆæƒä»¤ç‰Œæ— æ•ˆ'
            logger.warning(f'{msg}\n{week_response.text}')
            return {}
        last_week_response = requests.get(f'{url}&week=2', headers=headers, timeout=10)
        week_data = week_response.json().get('data')
        last_week_data = last_week_response.json().get('data')
        daka_dict = {}
        last_week_daka_dict = {}
        
        for member in week_data.get('list', []):
            id = member['uniqueId']
            daka_dict[id] = member['weekDakaDates']
        for member in last_week_data.get('list', []):
            id = member['uniqueId']
            last_week_daka_dict[id] = member['weekDakaDates']
        # åˆ†ç¦»è¿”å›
        if parsed:
            nickname_dict = {}
            for member in week_data.get('list', []):
                nickname_dict[member['uniqueId']] = member['nickname']
                data_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())
            self.buffered_daka_history[share_key] = {'data_time': data_time, 'this_week': daka_dict, 'last_week': last_week_daka_dict, 'group_nickname': nickname_dict}
            return self.buffered_daka_history.get(share_key)
        # å°†daka_dictå’Œlast_week_daka_dictåˆå¹¶è¿”å›
        for id, daka_dates in daka_dict.items():
            if id in last_week_daka_dict:
                last_week_daka_dict[id].extend(daka_dates)
            else:
                last_week_daka_dict[id] = daka_dates
        return last_week_daka_dict

    def updateGroupInfo(self, groups: list[dict], with_nickname: bool = True, only_favorite: bool = False) -> list:
        '''ã€å‚æ•°ä¼ å…¥çš„ç­å†…ä¸»é¡µã€‘è·å–æœ€æ–°ä¿¡æ¯å¹¶åˆ·æ–°å°ç­ä¿¡æ¯åˆ—è¡¨'''
        for i, group in enumerate(groups):
            if not group.get('valid'):
                groups.pop(i)
        results = self.getGroupsInfo(groups, with_nickname, only_favorite)
        for result in results:
            for group in groups:
                if group['id'] == result.get('id'):
                     group.update(result)
                elif group['share_key'] == result.get('share_key'):
                     group.update(result)
        return groups

    def getUserAllInfo(self, sqlite: SQLite, user_id: str, detail: int = 0) -> dict:
        '''ã€ç”¨æˆ·æ ¡ç‰Œ+æ‰€æœ‰å°ç­å†…ä¸»é¡µ+é»‘åå•ä¿¡æ¯ã€‘è·å–æŒ‡å®šç”¨æˆ·æ‰€æœ‰ä¿¡æ¯'''
        # ç›®å‰è¿™ä¸ªå‡½æ•°åœ¨ç­›é€‰å™¨å†…æ²¡æœ‰å¼•ç”¨ï¼Œä»…ç”¨ä½œå¤–éƒ¨æŸ¥è¯¢
        user_info = self.getUserInfo(user_id)
        if not user_info:
            return {}
        user_info['group_intro'] = self.getUserGroupInfo(user_id)
        user_info['black_list'] = sqlite.queryBlacklist(user_id)
        user_info['longest_info'] = sqlite.queryLongestInfo(user_id)
        if detail == 1:
            user_info['group_dict'] = self.getGroupsInfo(user_info['group_intro'])
        return user_info

def recordInfo(bcz: BCZ, sqlite: SQLite):
    '''è®°å½•ç”¨æˆ·ä¿¡æ¯'''
    groups = sqlite.queryObserveGroupInfo()
    for i, group in enumerate(groups):
        if not group['daily_record']:
            groups.pop(i)
    groups = bcz.getGroupsInfo(groups)
    member_count = sum([len(group.get('members', '')) for group in groups])
    sqlite.saveGroupInfo(groups)
    logger.info(f'æ¯æ—¥è®°å½•å·²å®Œæˆ, å·²è®°å½•{len(groups)}ä¸ªå°ç­, å…±{member_count}æ¡æ•°æ®')

def verifyInfo(bcz: BCZ, sqlite: SQLite, group_info: dict = {}) -> dict:
    '''é€šè¿‡å°ç­æˆå‘˜æ’è¡Œæ¦œè¡¥å…¨æ‰“å¡ä¿¡æ¯'''
    makeup_list = []
    local_sync_dict = {}
    quantity = 0
    if group_info != {}:
        groups = [group_info]
    else:
        groups = sqlite.queryObserveGroupInfo()
    for group in groups:
        if group['daily_record']:
            logger.info(f'æ­£åœ¨è·å–å°ç­[{group["name"]}({group["id"]})]çš„å†å²æ‰“å¡æ•°æ®')
            daka_dict = bcz.getGroupDakaHistory(group['share_key'])
            sdate = (datetime.now() - timedelta(days=7*2)).strftime('%Y-%m-%d')
            member_list = sqlite.queryMemberTable(
                {
                    'group_id': group['id'],
                    'sdate': sdate,
                    
                },
                header = False,
            )['data']
            absence_dict = {line[0]:line[4] for line in member_list if line[3] == ''}
            if not absence_dict:
                continue
            for id, daka_date in absence_dict.items():
                if id in daka_dict and daka_date in daka_dict[id]:
                    makeup_list.append({
                        'id': id,
                        'group_id': group['id'],
                        'today_date': daka_date,
                        'completed_time': 'æ™šäºè®°å½•æ—¶é—´',
                        'today_word_count': '?',
                    })
                    date_to_sync = local_sync_dict.get(group['id'], None)
                    if not date_to_sync:
                        local_sync_dict[group['id']] = [id]
                    elif daka_date not in date_to_sync:
                        date_to_sync.append(id)
                    quantity += 1
    logger.info(f'æœ¬æ¬¡æ£€æµ‹å¹¶è¡¥é½å†å²æ‰“å¡æ•°æ®{quantity}æ¡')
    sqlite.updateMemberInfo(makeup_list)
    return local_sync_dict

def refreshTempMemberTable(
        bcz: BCZ,
        sqlite: SQLite,
        group_id: str = '',
        only_valid: bool = True,
        latest: bool = False,
        with_nickname: bool = True,
        only_favorite: bool = False
    ) -> list[dict]:
    '''åˆ·æ–°æˆå‘˜ä¸´æ—¶è¡¨æ•°æ®å¹¶è¿”å›å°ç­æ•°æ®åˆ—è¡¨'''
    data_time = sqlite.queryTempMemberCacheTime()
    groups = sqlite.queryObserveGroupInfo(group_id, only_valid=only_valid)
    group_id_list = [group['id'] for group in groups if not (only_favorite and not group['favorite'])]
    if latest or (int(time.time()) - data_time > sqlite.config.cache_second or group_id):
        groups = bcz.updateGroupInfo(groups, with_nickname, only_favorite=only_favorite)
        sqlite.updateObserveGroupInfo(groups)
        today =  time.strftime('%Y-%m-%d', time.localtime())
        temp_data_date = sqlite.queryTempMemberCacheDate()
        if temp_data_date and today != temp_data_date:
            data_date_list = sqlite.queryMemberDataDateList()
            if temp_data_date not in data_date_list:
                sqlite.mergeTempMemberInfo()
        sqlite.deleteTempMemberTable(group_id_list)
        sqlite.saveGroupInfo(groups, temp=True)
    return groups

def analyseWeekInfo(groups: list[dict], sqlite: SQLite, week_date: str) -> list[dict]:
    '''åˆ†ææ‰“å¡æ•°æ®å¹¶è¿”å›'''
    if week_date:
        year, week = map(int, week_date.split('-W'))
    else:
        now = datetime.now()
        year, week = now.year, now.isocalendar()[1]
    start_of_year = date(year, 1, 1)
    start_of_week = start_of_year + timedelta(days=(week - 1) * 7 - start_of_year.weekday())
    sdate = start_of_week.strftime('%Y-%m-%d')
    end_of_week = start_of_week + timedelta(days=6)
    edate = end_of_week.strftime('%Y-%m-%d')
    is_this_week = False
    if start_of_week <= date.today() <= end_of_week:
        is_this_week = True
    for group in groups:
        group['week'] = week_date
        group['total_times'] = 0
        group['late_count'] = 0
        group['absence_count'] = 0

        if not group.get('members'):
            continue

        week_data = sqlite.queryMemberTable(
            {
                'group_id': group['id'],
                'sdate': sdate,
                'edate': edate,
                
            },
            header = False,
        )

        today_date = group['members'][0]['today_date']
        member_list = [member['id'] for member in group['members']]
        for line in week_data['data']:
            if line[0] not in member_list:
                member_list.append(line[0])
                group['members'].append(dict(zip(
                    [
                        'id',
                        'nickname',
                        'group_nickname',
                        'completed_time',
                        'today_date',
                        'today_word_count',
                        'today_study_cheat',
                        'completed_times',
                        'duration_days',
                        'book_name',
                        'group_id',
                        'group_name',
                        'avatar',
                        'data_time',
                    ],
                    [
                        line[0],
                        line[1],
                        line[2],
                        '',
                        today_date,
                        0,
                        False,
                        line[7],
                        line[8],
                        line[9],
                        line[10],
                        line[11],
                        line[12],
                        ''
                    ]
                )))

        for member in group['members']:
            daka_time_dict = {}
            late = 0
            absence = 0
            if is_this_week and member['completed_time']:
                group['total_times'] += 1
            for line in week_data['data']:
                if line[0] == member['id']:
                    if line[4] in daka_time_dict or line[4] == member['today_date']:
                        continue
                    daka_time_dict[line[4]] = {
                        'time': line[3],
                        'count': line[5],
                    }
                    if line[3] == '':
                        absence += 1
                    else:
                        group['total_times'] += 1
                    if group['late_daka_time'] and line[3] > group['late_daka_time']:
                        late += 1
            if late:
                group['late_count'] += 1
            if absence:
                group['absence_count'] += 1
            member.update({
                'daka': daka_time_dict,
                'late': late,
                'absence': absence,
            })

        # åˆ é™¤æ˜ŸæœŸå¤©ä¸åœ¨å°ç­çš„æˆå‘˜è´¡çŒ®çš„æ‰“å¡å¤©æ•°
        for member in group['members']:
            if member['data_time'] == '' and edate not in member['daka']:
                for daka_date in member['daka']:
                    daka = member['daka'][daka_date]
                    if daka['time']:
                        group['total_times'] -= 1
                    if group['late_daka_time'] and daka['time'] > group['late_daka_time']:
                        group['late_count'] -= 1


        # å¯¹æˆå‘˜è¿›è¡Œæ’åº
        list.sort(
            group['members'],
            key = lambda x: [
                1 if x['today_study_cheat'] == 'æ˜¯' else 0,
                x['absence'],
                x['late'],
            ],
            reverse=True
        )
    return groups

def getWeekOption(date: str = '', range_day: list[int] = [-180, 0]) -> list:
    '''è·å–æŒ‡å®šæ—¶é—´æŒ‡å®šèŒƒå›´å†…æ‰€æœ‰çš„å‘¨'''
    target_date = datetime.today()
    if date:
        try:    
            target_date = datetime.strptime(date, '%Y-%m-%d')
        except Exception as e:
            logger.warning(f'è½¬æ¢æ—¶é—´[{date}]å‡ºé”™: {e}')

    start_date = target_date + timedelta(days=range_day[0])
    end_date = target_date + timedelta(days=range_day[1])
    end_date_week_end = end_date - timedelta(days=end_date.weekday()) + timedelta(days=6)

    week_dict = {}
    current_date = start_date
    while current_date <= end_date_week_end:
        week_number = current_date.isocalendar()[1]
        week_start = current_date - timedelta(days=current_date.weekday())
        week_end = week_start + timedelta(days=6)
        week = f'{current_date.year}-W{week_number:02d}'
        week_str = f'{week_start.strftime("%mæœˆ%dæ—¥")} - {week_end.strftime("%mæœˆ%dæ—¥")} {current_date.year}å¹´ç¬¬{week_number:02d}å‘¨'
        week_dict[week] = week_str
        current_date += timedelta(7)
    return week_dict
